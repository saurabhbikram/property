---
title: "LondonSalesTurnover"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 6, fig.width = 10)
library(tidyverse)
library(DBI)
library(lubridate)
```

```{r}
MAKE_NEW = FALSE
get_creds <- function() {
  jstring <-
    system(
      "aws secretsmanager get-secret-value --secret-id prod/db1/app --region us-east-1 --output json",
      intern = T
    )
  res <-
    jsonlite::fromJSON(jsonlite::fromJSON(paste0(jstring, collapse = ""))$SecretString)
  return(res)
}
get_con <- function(res) {
  con <-
    RPostgres::dbConnect(
      RPostgres::Postgres(),
      user = res$username,
      password = res$password,
      host = res$host,
      dbname = "propertydata",
      bigint = "numeric"
    )
  return(con)
}

if(MAKE_NEW) {
  con <- get_con(get_creds())
  all_lisings <- tbl(con,"proc_listings") %>% collect()
  saveRDS(all_lisings, "allistings.rds")
  system("aws s3 cp allistings.rds s3://ukpd/property-analysis/alllistings.rds --profile sb")
} else {
  if(file.exists("alllistings.rds")) system("aws s3 cp s3://ukpd/property-analysis/alllistings.rds . --profile sb")
  all_lisings <- readRDS("alllistings.rds")
}
```



```{r}
# Set status of sold listings from LR
all_lisings$listing_status[!is.na(all_lisings$lang_reg_id)] <- "Sold (LR)"

# some data cleaning to get sales etc.
rawsales <- filter(all_lisings, str_detect(tolower(listing_status), "sold")) %>% 
  mutate(
    source=ifelse(is.na(source),"Zoopla",source) %>% factor(levels=c("LandRegistry","Zoopla")),
    sale_year =year(trans_date),
    incode=str_extract(postcode,"[A-Z]+"),
  ) %>% 
  arrange(source, desc(trans_date)) %>% 
  filter(!is.na(trans_date)) %>% 
  # we sometimes have sales twice, from each source or multiple sales from the same source
  # hence we remove any sales which happen between 250 days of a previous sale
  # since its unlikely a genuine sale happens twice in 250 days
  group_by(property_key) %>% 
  mutate(lag_sale=lag(trans_date), 
         time_diff=difftime(lag_sale, trans_date, units="days")
  ) %>% 
  filter(is.na(time_diff)|time_diff>250) %>% 
  ungroup

```

The scraping started in 2020, hence for sales since then we can get a more exact date of sale by looking at date scraped if the sale is *not* from Land Registry. This is an expensive loop but provides good data.

```{r}
rsales <- filter(rawsales, sale_year >= 2020)

# can only get sales of properties listed on zoopla, i.e. where the land registry sale could be matched to a zoopla listing based on address
length(str_subset(rsales$property_key,"land_reg",negate = T))
```

For properties where we know a for sale listing we can now calculate the listing date, sale date, prices. We can then calculate the time to sell and price reduction statistcs. The loop below takes care of that.

```{r cache=TRUE, cache.extra=Sys.Date()}
alist_all <- list()
for(x in str_subset(rsales$property_key,"land_reg",negate = T)) {
  
  # get all sales of the currrency property
  a <- filter(rawsales, property_key %in% x) %>% 
    arrange(desc(trans_date)) %>% 
    select(property_key, listing_key, trans_date,listing_date,date_scraped, listing_status, price, price_num)
  
  # get all listings which are not sales of the current property
  aa <- filter(all_lisings, property_key==x & 
                 (!str_detect(price,"pcm") | is.na(price)) & 
                 (price_num > 10e3 | is.na(price_num)) &
                 listing_status != "Listing expired" &
                 !str_detect(tolower(listing_status),"sold")
  ) %>% 
    distinct(property_key, listing_key, trans_date,listing_date,date_scraped, listing_status, price, price_num, area, beds) %>% 
    bind_rows(a) %>%  # attach historic cleaned sales
    arrange(desc(trans_date))
  
  if(nrow(aa)<=1) next()
  
  # remove any listings that happened before the 2nd last sale (if it exists)
  if(nrow(a) > 1) aa <- filter(aa, trans_date > a$trans_date[2])
  
  if(nrow(aa)<=1) next()
  
  # build the stats
  alist <- a[1,] %>% as.list()
  alist$min_price <- min(aa$price_num,na.rm = T)
  alist$max_price <- max(aa$price_num,na.rm = T)
  
  listing_dates <- aa %>% select(date_scraped,listing_date,trans_date) %>% unlist
  
  # default listing date
  alist$listed_date <- min(listing_dates,na.rm = T) %>% as.Date(origin="1970-01-01")
  
  # if know of a listing event, take that instead
  w <- tolower(aa$listing_status) %in% tolower(c("First listed","Listedforsale"))
  if(any(w)) {
    alist$listed_date <- min(aa$listing_date[w])
    if(is.na(alist$listed_date)) alist$listed_date <- aa$trans_date[w][1]
  }
  
  # default sale time is the last date seen scraped/listed
  alist$sale_time <- max(c(listing_dates, a$trans_date[1]),na.rm = T) %>% as.Date(origin="1970-01-01")  
  
  # unless we see a sold listing status and the trans date of this sold date
  # is different to listing date
  w <- aa$listing_status %in% c("Sold subject to contract","Sold", "Sold STC")
  if(any(w)) {
    trans_date <- min(aa$trans_date[w])
    if(trans_date != alist$listed_date) alist$sale_time <- trans_date
  }
  
  alist
  alist_all <- c(alist_all, list(alist))
  
}

# do some tidy up
about_sale <- bind_rows(alist_all) %>% 
  mutate(
    use_sale_time = ifelse(str_detect(listing_key,"land_reg"),trans_date, sale_time) %>% as.Date(origin="1970-01-01"),
    time_to_sell = difftime(use_sale_time,listed_date,units="days") %>% as.numeric,
    avg_price_reduction = price_num/max_price,
    avg_price_reduction = ifelse(is.infinite(avg_price_reduction) | avg_price_reduction < 0.5, NA, avg_price_reduction)
  ) %>% left_join(
    rawsales %>% select(listing_key, beds, area) %>% distinct(),by="listing_key"
  ) 

```

Top most time to sell properties. Some of these could just be because of incorrect data or people who listed for sale but never sold but then sold 5 years later!

```{r}
about_sale %>% 
  arrange(desc(time_to_sell)) %>% 
  select(listing_key, property_key,use_sale_time, listed_date, time_to_sell) %>% 
  head(25)
```

We have more accurate sale date from the loop above, so use that for the sale summaries.

```{r}
sales <- rawsales %>% 
  left_join(
    about_sale %>% select(listing_key, use_sale_time) %>% distinct(),
    by="listing_key"
  ) %>% 
  mutate(
    trans_date = ifelse(!is.na(use_sale_time),use_sale_time, trans_date) %>% as.Date("1970-01-01")
  ) %>% select(-use_sale_time)
```

Sale summaries by year & postcodes

```{r}
sumdf <- sales  %>% group_by(sale_year, incode) %>% 
  summarise(n=n(), 
            median_price=median(price_num),
            mean_price=mean(price_num)
  ) %>% 
  arrange(desc(sale_year))  %>% ungroup() %>% filter(sale_year > 2000)


sumdf %>% filter(sale_year %in% c(2019, 2020,2021))
```


```{r}
ggplot(sumdf, aes(sale_year, n, fill=incode)) + geom_col(aes(alpha=ifelse(sale_year %in% c(2020,2019),0.9,0.7))) +
  ggtitle("Number of sales per year in Central London") +
  theme_minimal() +
  theme(#axis.text.x = element_text(angle=90), 
    panel.grid.minor.x = element_blank(),
    panel.grid.major.x = element_blank()) +
  scale_x_continuous("", breaks=scales::pretty_breaks(n=10)) +
  scale_fill_brewer("Postcode",type="qual", palette = "Set2") +
  scale_y_continuous("Number of sales") +
  scale_alpha_continuous(guide='none')
```

```{r}
ggplot(sumdf %>% filter(sale_year < 2021), aes(sale_year, median_price)) + 
  geom_point() +
  geom_smooth(se=F, size=1) +
  facet_wrap("incode",ncol=2) +
  scale_y_continuous("median price", 
                     labels=function(x)scales::comma(x,prefix="£"), 
                     breaks=scales::pretty_breaks(n=5)) +
  ggtitle("Median sold prices per year in Central London") + scale_x_continuous("", labels=round)
```
```{r}
ggplot(sumdf %>% filter(sale_year < 2021), aes(sale_year, mean_price)) + 
  geom_point() +
  geom_smooth(se=F, size=1) +
  facet_wrap("incode",ncol=2) +
  scale_y_continuous("mean price", 
                     labels=function(x)scales::comma(x,prefix="£"), 
                     breaks=scales::pretty_breaks(n=5)) +
  ggtitle("Mean sold prices per year in Central London") + scale_x_continuous("", labels=round)
```
Add beds and do analysis by bedroom

```{r}
total_beds <- filter(all_lisings, property_key %in% sales$property_key) %>% 
  group_by(property_key) %>% 
  summarise(
    beds=round(mean(beds,na.rm=T))
  )
sales <- left_join(sales %>% select(-beds), total_beds, by="property_key")

sumdf <- sales %>% 
  group_by(sale_year, incode, beds=as.factor(ifelse(beds >= 3, "3+", as.character(beds)))) %>% 
  summarise(n=n(), 
            median_price=median(price_num,na.rm=T),
            mean_price=mean(price_num,na.rm=T)
  ) %>% 
  #filter(!is.na(beds)) %>% 
  arrange(desc(sale_year))  %>% ungroup() %>% filter(sale_year > 2000)

```
```{r}
# markdown function
source("vis_func.R")
```

Showing stats by bedroom and year

```{r}
sumdf %>% filter(incode=="EC", sale_year==2019)
```

```{r}
sumdf %>% filter(incode=="EC", sale_year==2020)
```


```{r}
ec2019 <- sumdf %>% filter(incode=="EC", sale_year==2019) %>% select(median_price, mean_price)
ec2020 <- sumdf %>% filter(incode=="EC", sale_year==2020) %>% select(median_price, mean_price)
sumdf %>% filter(incode=="EC", sale_year==2019) %>% select(beds) %>% cbind(100*round(ec2020/ec2019 - 1,3)) %>% 
  to_markdown()
```

```{r}
sumdf %>% filter(incode=="WC", sale_year==2019)
```

```{r}
sumdf %>% filter(incode=="WC", sale_year==2020)
```


```{r}
ec2019 <- sumdf %>% filter(incode=="WC", sale_year==2019) %>% select(median_price, mean_price)
ec2020 <- sumdf %>% filter(incode=="WC", sale_year==2020) %>% select(median_price, mean_price)
sumdf %>% filter(incode=="WC", sale_year==2019) %>% select(beds) %>% cbind(100*round(ec2020/ec2019 - 1,3)) %>% 
  to_markdown()
```

Stats about price reductions and time to sell

```{r}
about_sale %>% 
  mutate(
    beds=as.factor(ifelse(beds >= 3, "3+", as.character(beds)))
  ) %>% 
  group_by(beds) %>% 
  summarise(
    n=n(),
    median_price_reduction=(median(avg_price_reduction,na.rm=T)-1) %>% scales::percent(),
    median_time_to_sell=(median(time_to_sell,na.rm=T)/30.4) %>% round(1),
    prop_reduced=mean(avg_price_reduction<0.99,na.rm=T) %>% scales::percent(),
    prop_reduced_15=mean(avg_price_reduction<0.85,na.rm=T) %>% scales::percent(),
    prop_longer_9m_sell=mean(time_to_sell>270) %>% scales::percent()
  ) %>% filter(!is.na(beds)) %>% 
  to_markdown()
```


```{r}
plotdf <- about_sale %>% 
  filter(
    avg_price_reduction<1,
    time_to_sell > 10,
  ) %>% 
  mutate(
    beds=as.factor(ifelse(beds >= 3, "3+", as.character(beds)))
  )
ggplot(plotdf, 
       aes(time_to_sell/30, avg_price_reduction-1)) + geom_point(alpha=0.3) + 
  stat_smooth(method = "loess",method.args = list(family="symmetric")) +
  scale_y_continuous("Total reduction in price (highest price vs sold price)",
                     limits=c(-0.3,0), labels=scales::percent) +
  scale_x_continuous("months to sell",limits=c(0,24)) +
  ggtitle("Price reductions on EC & WC homes", subtitle = glue("from {nrow(plotdf)} price reduced sales made in the year {year(min(plotdf$sale_time))} and after"))
```
End


